import tiktoken
import openai

openai.api_key = "YOUR-OPENAI-KEY"

from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential,
)  # for exponential backoff



def num_tokens_from_messages(messages, model="gpt-3.5-turbo"):
    """Returns the number of tokens used by a list of messages."""
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base")
    if model == "gpt-3.5-turbo":
        num_tokens = 0
        for message in messages:
            num_tokens += 4
            for key, value in message.items():
                num_tokens += len(encoding.encode(value))
                if key == "name":
                    num_tokens += -1
        num_tokens += 2
        return num_tokens
    else:
        raise NotImplementedError(f"""num_tokens_from_messages() is not presently implemented for model {model}.
  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.""")


@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def summarize_code(code, debug=False):
    if not debug:
        prompt = f"provide a detailed code review of the following code snippet, and focus on security aspects:\n\n{code}\n\nResponse: "
        messages = [
            {"role": "system", "content": "You a helpful assistent with analyzing Java code snippets"},
            {"role": "system", "content": "You are a helpful assistent that detects security vulnerabilities"},
            {"role": "user", "content": prompt}
        ]
        completion = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages
        )

        if (num_tokens_from_messages(messages) > 4096):
            summary = "Too many tokens, max is 4096 \n"
        else:
            summary = completion.choices[0].message.content
        return summary
    else:
        return "No text generated"
